# copied from https://github.com/cablespaghetti/k3s-monitoring
# helm upgrade --install prometheus prometheus-community/kube-prometheus-stack --values kube-prometheus-stack-values.yaml

# references
# https://github.com/prometheus-community/helm-charts/blob/main/charts/kube-prometheus-stack/values.yaml

# Disable etcd monitoring. See https://github.com/cablespaghetti/k3s-monitoring/issues/4
kubeEtcd:
  enabled: false

# Disable kube-controller-manager and kube-scheduler monitoring. See https://github.com/cablespaghetti/k3s-monitoring/issues/2
# and https://github.com/prometheus-community/helm-charts/pull/626
kubeControllerManager:
  enabled: false
kubeScheduler:
  enabled: false

alertmanager:
  config:
    # global:
    #  smtp_smarthost: smtp.gmail.com:587
    #  smtp_auth_username: you@gmail.com
    #  smtp_auth_password: yourapppassword # https://support.google.com/mail/answer/185833?hl=en-GB
    #  smtp_auth_identity: you@gmail.com
    route:
      group_by: ["job"]
      group_wait: 30s
      group_interval: 5m
      repeat_interval: 1h
      receiver: "null"
      routes:
        - match:
            alertname: Watchdog
          receiver: "null"
        - match:
            alertname: CPUThrottlingHigh
          receiver: "null"
        - match:
            alertname: KubeMemoryOvercommit
          receiver: "null"
        - match:
            alertname: KubeCPUOvercommit
          receiver: "null"
        - match:
            alertname: KubeletTooManyPods
          receiver: "null"

    receivers:
      - name: "null"

    # Inhibition rules allow to mute a set of alerts given that another alert is firing.
    # We use this to mute any warning-level notifications if the same alert is already critical.
    inhibit_rules:
      - source_match:
          severity: "critical"
        target_match:
          severity: "warning"
        # Apply inhibition if the alertname is the same.
        equal: ["alertname", "namespace"]

  ingress:
    enabled: true
    annotations:
      traefik.ingress.kubernetes.io/rewrite-target: /
    hosts:
      - nasbox.fritz.box
    paths:
      - /alertmanager

  alertmanagerSpec:
    externalUrl: "http://nasbox.fritz.box/alertmanager/"
    #    replicas: 3
    #    podAntiAffinity: "soft"
    nodeSelector:
      kubernetes.io/hostname: nasbox
    storage:
      volumeClaimTemplate:
        spec:
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 1Gi
    resources:
      requests:
        cpu: 25m
        memory: 32Mi

prometheus:
  ingress:
    enabled: true
    annotations:
      traefik.ingress.kubernetes.io/rewrite-target: /
    hosts:
      - nasbox.fritz.box
    paths:
      - /prometheus

  prometheusSpec:
    retention: 7d
    externalUrl: "http://nasbox.fritz.box/prometheus/"

    #    replicas: 2
    #    podAntiAffinity: "hard"
    nodeSelector:
      kubernetes.io/hostname: nasbox
    storageSpec:
      volumeClaimTemplate:
        spec:
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 10Gi

    resources:
      requests:
        cpu: 200m
        memory: 400Mi

  additionalServiceMonitors:
    - name: prometheus-lt-kube-prometh-prometheus
      selector:
        matchLabels:
          app: kube-prometheus-stack-prometheus
          release: prometheus-lt
      endpoints:
        - path: /metrics
          port: web
    - name: traefik
      endpoints:
        - port: metrics
      namespaceSelector:
        matchNames:
          - kube-system
      selector:
        matchLabels:
          app: traefik
    - name: pvcontrol
      endpoints:
        - path: /metrics
          port: tcp
      selector:
        matchLabels:
          app: pvcontrol
    - name: modbus-exporter
      endpoints:
        - path: /metrics
          port: tcp
        - path: /modbus
          port: tcp
          params:
            target: ["scb.fritz.box:1502"]
            module: ["kostal-inverter"]
            sub_target: ["71"] # Modbus unit identifier
          relabelings:
            - sourceLabels: [__param_target]
              targetLabel: instance
      selector:
        matchLabels:
          app: modbus-exporter

additionalPrometheusRulesMap:
  prometheus-node-exporter.rules:
    groups:
      - name: node-exporter-lt.rules
        rules:
          - record: instance:node_memory_MemAvailable_bytes:avg15m
            expr: avg_over_time(node_memory_MemAvailable_bytes[15m])

grafana:
  plugins:
    - grafana-piechart-panel
    - flant-statusmap-panel
  grafana.ini:
    server:
      domain: nasbox.fritz.box
      root_url: "%(protocol)s://%(domain)s/grafana"
      serve_from_sub_path: true
    auth.anonymous:
      enabled: true
      org_name: Main Org.
      org_role: Viewer
  ingress:
    enabled: true
    hosts:
      - nasbox.fritz.box
    path: /grafana
  additionalDataSources:
    # prometheus-lt instances deployed separately
    - name: prometheus-lt
      type: prometheus
      url: http://prometheus-lt-kube-prometh-prometheus:9090/
      access: proxy
      jsonData:
        timeInterval: 15m
  resources:
    requests:
      cpu: 25m
      memory: 64Mi
  sidecar:
    resources:
      requests:
        cpu: 5m
        memory: 64Mi

prometheusOperator:
  nodeSelector:
    kubernetes.io/hostname: nasbox
  resources:
    requests:
      cpu: 50m
      memory: 128Mi

prometheus-node-exporter:
  resources:
    requests:
      cpu: 10m
      memory: 16Mi

kube-state-metrics:
  nodeSelector:
    kubernetes.io/hostname: nasbox
  resources:
    requests:
      cpu: 5m
      memory: 64Mi
